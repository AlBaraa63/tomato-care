# ğŸ… TomatoCare: AI-Powered Tomato Disease Detection

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-91.2%25-brightgreen.svg)
![Mobile Ready](https://img.shields.io/badge/Mobile-Ready-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

> **Custom CNN from Scratch** for Real-Time Tomato Disease Classification on Mobile Devices

---

## ğŸ¯ Executive Summary

Tomato diseases cause **25â€“50% of annual crop losses** globally, threatening food security and home gardening sustainability. Traditional diagnosis requires expert knowledge and is error-prone, especially for visually similar diseases.

**TomatoCare** is a lightweight, mobile-optimized AI solution that:
- Classifies **10 tomato diseases + healthy** from leaf images
- Achieves **91.2% accuracy** on unseen test data
- Uses a **custom architecture built from scratch** (no transfer learning)
- Runs **offline on mobile devices** (Android/iOS ready)

---

## ğŸ† Key Achievements

| Achievement | Details |
|-------------|---------|
| **ğŸ¯ High Accuracy** | **91.2%** on diverse test set (31k+ images) |
| **ğŸ§  Custom Architecture** | `TomatoCareNet` with Residual Connections + SE Attention |
| **ğŸ“± Mobile-Optimized** | Lightweight design (~2-3MB after quantization) |
| **ğŸ“Š Massive Dataset** | **31,278 images** merged from 4 sources (Lab + Field) |
| **ğŸ” Explainable AI** | Grad-CAM heatmaps show disease regions |
| **âš¡ Advanced Training** | Focal Loss, MixUp, AMP, Cosine Annealing |

---

## ğŸ“Š Dataset Strategy

### Multi-Source Data Fusion
We merged **4 major datasets** to create a robust training set that handles both lab and real-world conditions:

| Source | Images | Type | Purpose |
|--------|--------|------|---------|
| **PlantVillage** | ~14,500 | Lab (controlled) | High-quality baseline |
| **PlantDoc** | ~400 | Real-world | Background diversity |
| **TomatoVillage** | ~1,000 | Field | Deployment-like conditions |
| **Mendeley Taiwan** | ~5,000 | Field + Lab | Cross-region variety |

### Dataset Split (70/15/15)

After merging, deduplication, and balancing, we have:

| Class | Train | Val | Test | Total |
|-------|-------|-----|------|-------|
| Bacterial Spot | 2,490 | 533 | 535 | 3,558 |
| Early Blight | 2,168 | 464 | 466 | 3,098 |
| Healthy | 2,699 | 578 | 579 | 3,856 |
| Late Blight | 2,733 | 585 | 587 | 3,905 |
| Leaf Mold | 2,445 | 523 | 525 | 3,493 |
| Septoria Leaf Spot | 2,539 | 544 | 545 | 3,628 |
| Spider Mites | 1,527 | 327 | 328 | 2,182 |
| Target Spot | 1,598 | 342 | 344 | 2,284 |
| Yellow Leaf Curl Virus | 1,775 | 380 | 382 | 2,537 |
| Tomato Mosaic Virus | 1,915 | 410 | 412 | 2,737 |
| **Total** | **21,889** | **4,686** | **4,703** | **31,278** |

### Class Balancing Techniques
- **Focal Loss** (Î³=2.0) to focus on hard-to-classify samples
- **Class Weights** to account for remaining imbalance
- **Heavy Augmentation** on minority classes
- **MixUp** for better generalization

---

## ğŸ§  Model Architecture: TomatoCareNet

### Design Philosophy
- **From Scratch** â€” No pre-trained weights, fully trained on our merged dataset
- **Lightweight** â€” Optimized for mobile deployment
- **Attention-Enhanced** â€” SE (Squeeze-and-Excitation) blocks for channel-wise focus
- **Residual Learning** â€” Skip connections for gradient flow

### Architecture Overview

```
Input: 224Ã—224Ã—3 (RGB Image)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLOCK 1: Low-level Features (Edges)        â”‚
â”‚  Conv3x3(3â†’32) + BN + ReLU                  â”‚
â”‚  Conv3x3(32â†’32) + BN + Residual + Pool      â”‚
â”‚  Dropout(0.2)                               â”‚
â”‚  Output: 112Ã—112Ã—32                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLOCK 2: Mid-level Features (Textures)     â”‚
â”‚  Conv3x3(32â†’64) + BN + ReLU                 â”‚
â”‚  Conv3x3(64â†’64) + BN + Residual + Pool      â”‚
â”‚  Dropout(0.25)                              â”‚
â”‚  Output: 56Ã—56Ã—64                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLOCK 3: High-level Features (Patterns)    â”‚
â”‚  Conv3x3(64â†’128) + BN + ReLU                â”‚
â”‚  Conv3x3(128â†’128) + BN + Residual + Pool    â”‚
â”‚  Dropout(0.3)                               â”‚
â”‚  Output: 28Ã—28Ã—128                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BLOCK 4: Abstract Features (Disease Cues)  â”‚
â”‚  Conv3x3(128â†’256) + BN + ReLU               â”‚
â”‚  Conv3x3(256â†’256) + BN + Residual + Pool    â”‚
â”‚  Dropout(0.3)                               â”‚
â”‚  Output: 14Ã—14Ã—256                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SE ATTENTION: Channel Recalibration        â”‚
â”‚  GlobalAvgPool â†’ FC(16) â†’ ReLU â†’ FC(256)    â”‚
â”‚  â†’ Sigmoid â†’ Multiply                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLASSIFIER                                 â”‚
â”‚  GlobalAvgPool â†’ Flatten                    â”‚
â”‚  FC(256â†’512) + BN + ReLU + Dropout(0.5)     â”‚
â”‚  FC(512â†’256) + BN + ReLU + Dropout(0.4)     â”‚
â”‚  FC(256â†’10) â†’ Softmax                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
     10 Class Probabilities
```

### Key Design Decisions

| Component | Rationale |
|-----------|-----------|
| **Residual Connections** | Enable gradient flow, improve convergence from scratch |
| **SE Blocks** | Channel attention helps focus on disease-relevant features |
| **Global Average Pooling** | Reduces params by 50k+ vs. flattening, acts as regularizer |
| **Progressive Channels** | 32â†’64â†’128â†’256 gradually captures complexity |
| **Heavy Dropout** | Critical for preventing overfitting on lab images |

**Model Size:** ~2.5M parameters (~10MB float32, **~2-3MB int8 quantized**)

---

## ğŸ“ˆ Performance Results

### Training Curves

![Training History](results/plots/training_history.png)

**Key Observations:**
- Steady convergence with minimal overfitting
- Validation accuracy plateaus around **91.2%**
- Learning rate warmup (5 epochs) + cosine annealing ensures stable training

### Confusion Matrix (Test Set)

![Confusion Matrix](results/plots/confusion_matrix.png)

**Analysis:**
- **Strong diagonal** â€” most predictions are correct
- **Minimal confusion** between Early Blight â†” Target Spot (both have ring patterns)
- **Healthy class:** 95%+ precision (low false alarms)

### Test Augmentation (TTA)

![Confusion Matrix with TTA](results/plots/confusion_matrix_tta.png)

Using Test-Time Augmentation (5 crops + flips), accuracy improves to **~92.5%**.

---

## âš™ï¸ Training Configuration

| Hyperparameter | Value |
|----------------|-------|
| **Optimizer** | AdamW (weight decay=1e-4) |
| **Learning Rate** | 1e-3 with warmup (5 epochs) + cosine annealing |
| **Loss Function** | Focal Loss (Î³=2.0) + Label Smoothing (0.1) |
| **Batch Size** | 64 |
| **Augmentation** | Rotation, Flip, Brightness, MixUp (Î±=0.2) |
| **Mixed Precision** | AMP enabled (CUDA) |
| **Gradient Clipping** | Max norm = 1.0 |
| **Early Stopping** | Patience = 15 epochs |

---

## ğŸš€ Installation & Usage

### Prerequisites
- Python 3.10+
- CUDA-capable GPU (recommended)

### Step 1: Install PyTorch with CUDA
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```
*(Adjust `cu124` to match your CUDA version)*

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Train the Model
```bash
python main.py
```

**Outputs:**
- Best model: `models/checkpoints/best_model.pth`
- Logs: `results/tensorboard/`
- Plots: `results/plots/`

### Step 4: Evaluate
```bash
python -m src.evaluate
```

---

## ğŸ“ Project Structure

```
TomatoCare/
â”‚
â”œâ”€â”€ data/                        â† ALL dataset-related files live here
â”‚   â”œâ”€â”€ raw/                     â† Original downloaded datasets (NEVER modify these)
â”‚   â”‚   â”œâ”€â”€ PlantVillage/        â† ~14,500 lab images (10 classes)
â”‚   â”‚   â”œâ”€â”€ PlantDoc/            â† ~400 real-world images
â”‚   â”‚   â”œâ”€â”€ TomatoVillage/       â† ~1,000 field images
â”‚   â”‚   â””â”€â”€ Mendeley/            â† ~5,000 Taiwan field images
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/               â† Cleaned, merged, and split dataset
â”‚   â”‚   â”œâ”€â”€ train/               â† 70% of data (model learns from this)
â”‚   â”‚   â”‚   â”œâ”€â”€ Bacterial_spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Early_blight/
â”‚   â”‚   â”‚   â”œâ”€â”€ Late_blight/
â”‚   â”‚   â”‚   â”œâ”€â”€ Leaf_Mold/
â”‚   â”‚   â”‚   â”œâ”€â”€ Septoria_leaf_spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Spider_mites/
â”‚   â”‚   â”‚   â”œâ”€â”€ Target_Spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Tomato_Yellow_Leaf_Curl_Virus/
â”‚   â”‚   â”‚   â”œâ”€â”€ Tomato_mosaic_virus/
â”‚   â”‚   â”‚   â””â”€â”€ Healthy/
â”‚   â”‚   â”œâ”€â”€ val/                 â† 15% of data (model checks itself during training)
â”‚   â”‚   â”‚   â””â”€â”€ (same 10 class folders)
â”‚   â”‚   â””â”€â”€ test/                â† 15% of data (final exam â€” model never sees this until the end)
â”‚   â”‚       â””â”€â”€ (same 10 class folders)
â”‚   â”‚
â”‚   â””â”€â”€ augmented/               â† Extra images created by augmentation (rotated, flipped, etc.)
â”‚
â”œâ”€â”€ notebooks/                   â† Jupyter notebooks (our step-by-step experiments)
â”‚   â””â”€â”€ 01_EDA.ipynb             â† Explore & understand the data
â”‚
â”œâ”€â”€ src/                         â† Reusable Python code (functions we use across the project)
â”‚   â”œâ”€â”€ __init__.py              â† Makes this folder a Python package
â”‚   â”œâ”€â”€ config.py                â† Central configuration (hyperparameters, paths, device settings)
â”‚   â”œâ”€â”€ data_loader.py           â† Custom Dataset class and data loading functions
â”‚   â”œâ”€â”€ model.py                 â† Our custom CNN architecture (TomatoCareNet)
â”‚   â”œâ”€â”€ train.py                 â† Training loop with FocalLoss, MixUp, AMP, early stopping
â”‚   â”œâ”€â”€ evaluate.py              â† Evaluation metrics, TTA, and plots
â”‚   â”œâ”€â”€ gradcam.py               â† Grad-CAM explainability functions
â”‚   â”œâ”€â”€ data_prep/               â† One-off scripts for dataset preparation
â”‚   â”‚   â”œâ”€â”€ extract_archive.py   â† Extract downloaded archives
â”‚   â”‚   â”œâ”€â”€ extract_zip.py       â† Extract zip files
â”‚   â”‚   â”œâ”€â”€ consolidate_datasets.py â† Merge all sources into one structure
â”‚   â”‚   â”œâ”€â”€ split_data.py        â† Split into train/val/test (70/15/15)
â”‚   â”‚   â”œâ”€â”€ check_duplicates.py  â† Find duplicate images
â”‚   â”‚   â””â”€â”€ remove_duplicates.py â† Remove duplicate images
â”‚   â”œâ”€â”€ utils/                   â† Utility functions
â”‚   â”‚   â”œâ”€â”€ augmentation.py      â† Data augmentation functions (Albumentations)
â”‚   â”‚   â””â”€â”€ calculate_weights.py â† Compute class weights for loss function
â”‚   â””â”€â”€ visualization/           â† Standalone visualization scripts
â”‚       â”œâ”€â”€ visualize_dataset.py â† Visualize dataset distributions
â”‚       â”œâ”€â”€ visualize_augmentation.py â† Preview augmentation effects
â”‚       â”œâ”€â”€ visualize_final_data.py   â† Final dataset visualizations
â”‚       â””â”€â”€ compare_datasets.py  â† Compare dataset sources
â”‚
â”œâ”€â”€ models/                      â† Saved model files
â”‚   â”œâ”€â”€ checkpoints/             â† Auto-saved during training (best weights so far)
â”‚   â”‚   â””â”€â”€ best_model.pth       â† Best PyTorch checkpoint
â”‚   â”œâ”€â”€ final/                   â† The finished trained model
â”‚   â”‚   â””â”€â”€ tomatocare_final.pth â† Final PyTorch model
â”‚   â””â”€â”€ mobile/                  â† Converted for mobile/edge deployment
â”‚       â””â”€â”€ tomatocare.onnx      â† ONNX format for cross-platform inference
â”‚
â”œâ”€â”€ results/                     â† All output results
â”‚   â”œâ”€â”€ plots/                   â† Training curves, data distribution charts
â”‚   â”œâ”€â”€ metrics/                 â† Accuracy, F1, confusion matrices (saved as CSV/JSON)
â”‚   â”œâ”€â”€ gradcam/                 â† Grad-CAM heatmap images
â”‚   â”œâ”€â”€ comparison/              â† Dataset comparison visualizations
â”‚   â”œâ”€â”€ final_visualization/     â† Final dataset visualizations
â”‚   â”œâ”€â”€ reports/                 â† Generated reports
â”‚   â””â”€â”€ tensorboard/             â† TensorBoard training logs
â”‚
â”œâ”€â”€ docs/                        â† Documentation and reports
â”‚   â”œâ”€â”€ TomatoCare_Research.md   â† Our research document
â”‚   â”œâ”€â”€ TomatoCare_Training_Plan.md â† Training strategy plan
â”‚   â””â”€â”€ duplicate_report.txt     â† Duplicate detection report
â”‚
â”œâ”€â”€ main.py                      â† Entry point â€” runs the full training pipeline
â”œâ”€â”€ README.md                    â† This file â€” project overview
â””â”€â”€ requirements.txt             â† Python packages needed to run the project
```

---

## ğŸ”¬ Tech Stack

| Category | Technologies |
|----------|-------------|
| **Core** | Python 3.10+ |
| **Deep Learning** | PyTorch, torchvision, torchaudio |
| **Computer Vision** | OpenCV, Albumentations |
| **Visualization** | Matplotlib, Seaborn, TensorBoard |
| **Data Science** | NumPy, Pandas, scikit-learn |
| **Deployment** | ONNX (coming soon) |

---

## ğŸ“ Research Context

This project is part of my **Capstone Project** at **Al Ain University**, demonstrating:
1. **End-to-end ML pipeline** â€” data collection â†’ training â†’ evaluation
2. **Custom architecture design** â€” not just using pre-trained models
3. **Real-world applicability** â€” mobile deployment for UAE home gardeners
4. **Explainable AI** â€” Grad-CAM for interpretability

For detailed research background, see [`docs/TomatoCare_Research.md`](docs/TomatoCare_Research.md).

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- **PlantVillage Team** for the foundational dataset
- **PlantDoc contributors** for real-world image diversity
- **PyTorch Community** for excellent documentation
- **Al Ain University** for supporting this research

---

**Built with â¤ï¸ for sustainable agriculture and food security.**
