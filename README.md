# ğŸ… TomatoCare â€” Project Structure

## What is this?
This is the folder structure for our TomatoCare project. Every folder has a 
specific purpose, so we always know where to find things.

## Folder Map

```
TomatoCare/
â”‚
â”œâ”€â”€ data/                        â† ALL dataset-related files live here
â”‚   â”œâ”€â”€ raw/                     â† Original downloaded datasets (NEVER modify these)
â”‚   â”‚   â”œâ”€â”€ PlantVillage/        â† ~14,500 lab images (10 classes)
â”‚   â”‚   â”œâ”€â”€ PlantDoc/            â† ~400 real-world images 
â”‚   â”‚   â”œâ”€â”€ TomatoVillage/       â† ~1,000 field images
â”‚   â”‚   â””â”€â”€ Mendeley/            â† ~5,000 Taiwan field images
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/               â† Cleaned, merged, and split dataset
â”‚   â”‚   â”œâ”€â”€ train/               â† 70% of data (model learns from this)
â”‚   â”‚   â”‚   â”œâ”€â”€ Bacterial_Spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Early_Blight/
â”‚   â”‚   â”‚   â”œâ”€â”€ Late_Blight/
â”‚   â”‚   â”‚   â”œâ”€â”€ Leaf_Mold/
â”‚   â”‚   â”‚   â”œâ”€â”€ Septoria_Leaf_Spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Spider_Mites/
â”‚   â”‚   â”‚   â”œâ”€â”€ Target_Spot/
â”‚   â”‚   â”‚   â”œâ”€â”€ Yellow_Leaf_Curl_Virus/
â”‚   â”‚   â”‚   â”œâ”€â”€ Mosaic_Virus/
â”‚   â”‚   â”‚   â””â”€â”€ Healthy/
â”‚   â”‚   â”œâ”€â”€ val/                 â† 15% of data (model checks itself during training)
â”‚   â”‚   â”‚   â””â”€â”€ (same 10 class folders)
â”‚   â”‚   â””â”€â”€ test/                â† 15% of data (final exam â€” model never sees this until the end)
â”‚   â”‚       â””â”€â”€ (same 10 class folders)
â”‚   â”‚
â”‚   â””â”€â”€ augmented/               â† Extra images created by augmentation (rotated, flipped, etc.)
â”‚
â”œâ”€â”€ notebooks/                   â† Jupyter notebooks (our step-by-step experiments)
â”‚   â”œâ”€â”€ 01_EDA.ipynb             â† Step 1: Explore & understand the data
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb   â† Step 2: Clean, merge, split the datasets
â”‚   â”œâ”€â”€ 03_model_v1.ipynb        â† Step 3: Build & train first model version
â”‚   â”œâ”€â”€ 04_model_v2.ipynb        â† Step 4: Improve the model
â”‚   â”œâ”€â”€ 05_evaluation.ipynb      â† Step 5: Test & analyze results
â”‚   â””â”€â”€ 06_gradcam.ipynb         â† Step 6: Explainability visualizations
â”‚
â”œâ”€â”€ src/                         â† Reusable Python code (functions we use across notebooks)
â”‚   â”œâ”€â”€ __init__.py              â† Makes this folder a Python package
â”‚   â”œâ”€â”€ data_loader.py           â† Functions to load and prepare images
â”‚   â”œâ”€â”€ augmentation.py          â† Data augmentation functions
â”‚   â”œâ”€â”€ model.py                 â† Our custom CNN architecture (TomatoCareNet)
â”‚   â”œâ”€â”€ train.py                 â† Training loop and callbacks
â”‚   â”œâ”€â”€ evaluate.py              â† Evaluation metrics and plots
â”‚   â””â”€â”€ gradcam.py               â† Grad-CAM explainability functions
â”‚
â”œâ”€â”€ models/                      â† Saved model files
â”‚   â”œâ”€â”€ checkpoints/             â† Auto-saved during training (best weights so far)
â”‚   â””â”€â”€ final/                   â† The finished trained model
â”‚       â”œâ”€â”€ tomatocare_best.h5   â† Best Keras model
â”‚       â””â”€â”€ tomatocare.tflite    â† Converted for mobile deployment
â”‚
â”œâ”€â”€ results/                     â† All output results
â”‚   â”œâ”€â”€ plots/                   â† Training curves, data distribution charts
â”‚   â”œâ”€â”€ metrics/                 â† Accuracy, F1, confusion matrices (saved as CSV/JSON)
â”‚   â””â”€â”€ gradcam/                 â† Grad-CAM heatmap images
â”‚
â”œâ”€â”€ app/                         â† Mobile app code (Flutter/React Native â€” later phase)
â”‚
â”œâ”€â”€ docs/                        â† Documentation and reports
â”‚   â””â”€â”€ TomatoCare_Research.md   â† Our research document
â”‚
â”œâ”€â”€ README.md                    â† This file â€” project overview
â””â”€â”€ requirements.txt             â† Python packages needed to run the project
```

## Why This Structure?

### ğŸ”‘ Key Principles:

1. **`raw/` is sacred** â€” We NEVER modify original downloaded data. If something goes 
   wrong with processing, we can always start fresh from raw data.

2. **`processed/` is our working dataset** â€” After merging all sources, cleaning, and 
   splitting into train/val/test, this is what the model actually uses.

3. **`notebooks/` are numbered** â€” So anyone (including future-you) can follow the 
   project step by step, in order.

4. **`src/` avoids code duplication** â€” Instead of copying the same function into every 
   notebook, we write it once in `src/` and import it everywhere.

5. **`models/checkpoints/` saves progress** â€” Training can take hours. If it crashes at 
   epoch 80, we don't lose the best model from epoch 65.

6. **`results/` is for evidence** â€” Every plot, metric, and visualization is saved here.
   This is what goes into your capstone report.

## The Data Pipeline (How Data Flows)

```
Step 1: Download         Step 2: Merge & Clean      Step 3: Split
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ data/raw/        â”‚     â”‚ Merge all sourcesâ”‚     â”‚ train/ (70%) â”‚
â”‚  PlantVillage/   â”‚â”€â”€â”€â”€â–¶â”‚ Resize to 224x224â”‚â”€â”€â”€â”€â–¶â”‚ val/   (15%) â”‚
â”‚  PlantDoc/       â”‚     â”‚ Fix labels       â”‚     â”‚ test/  (15%) â”‚
â”‚  TomatoVillage/  â”‚     â”‚ Remove duplicatesâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Mendeley/       â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â–¼
                                                  Step 4: Augment
                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚ Rotate, flip, â”‚
                                                  â”‚ brightness,   â”‚
                                                  â”‚ zoom, noise   â”‚
                                                  â”‚ (train only!) â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                                  Step 5: Train
                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚ Feed into CNN â”‚
                                                  â”‚ TomatoCareNet â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Important:** We ONLY augment training data, never validation or test data.
Validation and test must reflect real-world conditions to give honest results.

## Getting Started

```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step 2: Download datasets into data/raw/ (see notebooks/01_EDA.ipynb)

# Step 3: Follow the notebooks in order (01, 02, 03...)
```

## Tech Stack
- **Python 3.10+**
- **TensorFlow / Keras** â€” Deep learning framework
- **OpenCV** â€” Image processing
- **Matplotlib / Seaborn** â€” Visualization
- **scikit-learn** â€” Metrics and data splitting
- **Albumentations** â€” Advanced image augmentation
- **NumPy / Pandas** â€” Data handling